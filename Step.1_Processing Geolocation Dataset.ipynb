{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc9f105-d532-48ae-bce6-e35356c14692",
   "metadata": {},
   "source": [
    "# Step.1 Processing Geolocation Dataset:  \n",
    "Due to the time-consuming nature of processing the geolocation dataset, an additional process is required. The final file will be saved as **'olist_geolocation_dataset_2.0'**. Subsequent uses of geolocation data will load from version 2.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ed5b4d-d3f3-41be-91bf-17919c8476dd",
   "metadata": {},
   "source": [
    "**1.1 Import neccesary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccce3d87-cfb8-40b1-8e2c-3d49709b4ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#for checking misspells\n",
    "from fuzzywuzzy import fuzz\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6648686-7da0-4041-92f2-04ef231c90a3",
   "metadata": {},
   "source": [
    "**1.2 Read the geolocation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc52588f-b7fe-45b0-8d09-4eb766e86357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geolocation = pd.read_csv(\"olist_geolocation_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56dd9e-85f9-4b3f-adf0-a187e8db0b67",
   "metadata": {},
   "source": [
    "**1.3 Combining rows with same zipcode:**  \n",
    "Each zip code has more than one latitude and longitude, so average the latitude and longitude of each zip code to leave one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e75dc5e-79a5-4300-b3b1-efe435e99727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geolocation = df_geolocation.groupby('geolocation_zip_code_prefix').agg({\n",
    "    'geolocation_lat': 'mean',\n",
    "    'geolocation_lng': 'mean',\n",
    "    # remain the first state\n",
    "    'geolocation_state': 'first',\n",
    "    # remain the first city\n",
    "    'geolocation_city': 'first'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca51e4-22c8-4bf2-9fe5-abe2cab8b0f2",
   "metadata": {},
   "source": [
    "**1.4 Processing spelling inconsistencies in 'City' Column:**  \n",
    "In the city column, some cities representing the same area are displayed in different formats within the dataset. To maintain data consistency, the city field will be normalized first.For example, SÃ£o Paulo, Sao Paulo, and San Paulo refer to the same city but may be displayed differently in the dataset. Therefore, we will process these entries to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa909584-cc69-49e8-ad52-4a7e3249f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize function to remove accents and diacritical marks, useful for standardising text data\n",
    "def normalize_string(s):\n",
    "    return unidecode.unidecode(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7718783d-7f3d-4611-96be-f17e1cd26f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique city names\n",
    "unique_cities = df_geolocation['geolocation_city'].unique()\n",
    "\n",
    "# Apply the normalize_string function to the 'geolocation_city' column\n",
    "df_geolocation['normalized_city'] = df_geolocation['geolocation_city'].apply(normalize_string)\n",
    "\n",
    "# Function to find similar cities (use normalized version for both)\n",
    "def find_similar_cities(city_name, unique_normalized_cities, threshold=95):\n",
    "    similar_cities = []\n",
    "    for other_city in unique_normalized_cities:\n",
    "        # Compare the normalized city names directly (no need to normalize again)\n",
    "        similarity = fuzz.ratio(city_name, other_city)\n",
    "        if similarity >= threshold:\n",
    "            similar_cities.append(other_city)\n",
    "    return similar_cities\n",
    "\n",
    "# Create a dictionary to store the mapping of misspellings to corrected city names\n",
    "city_mapping = {}\n",
    "\n",
    "# Get the unique normalized city names from the DataFrame (no need to normalize again)\n",
    "unique_normalized_cities = df_geolocation['normalized_city'].unique()\n",
    "\n",
    "# Iterate through the unique normalized cities to find similar ones\n",
    "for city in unique_normalized_cities:\n",
    "    similar_cities = find_similar_cities(city, unique_normalized_cities)\n",
    "    if len(similar_cities) > 1:  # If more than one similar city exists\n",
    "        # Choose the city with the accented version as the \"correct\" one\n",
    "        # Here we use the original, non-normalized city names for the mapping\n",
    "        corrected_city = max(similar_cities, key=lambda x: fuzz.ratio(x, city))  # pick the version with better match\n",
    "        for similar_city in similar_cities:\n",
    "            if similar_city != corrected_city:\n",
    "                city_mapping[similar_city] = corrected_city  # map misspelled version to correct version\n",
    "\n",
    "# Create a new column with the corrected city names\n",
    "df_geolocation['corrected_city'] = df_geolocation['normalized_city'].map(city_mapping).fillna(df_geolocation['normalized_city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d69a92-d738-4ec0-8008-51b2ba1b394a",
   "metadata": {},
   "source": [
    "**1.5 Save as a new file named: olist_geolocation_dataset_2.0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2780ed45-51ef-49cd-87a4-05183a6c041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geolocation.to_csv('olist_geolocation_dataset_2.0.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
